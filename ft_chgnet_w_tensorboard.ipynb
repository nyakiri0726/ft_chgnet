{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chgnet.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1646131108.py, line 99)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[27], line 99\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from chgnet.model.model import CHGNet\n",
    "from typing import Literal\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "\n",
    "class TrainerV2(Trainer):\n",
    "    def __init__(self, model: CHGNet | None = None, targets: Literal['ef', 'efs', 'efsm'] = \"ef\", energy_loss_ratio: float = 1, force_loss_ratio: float = 1, stress_loss_ratio: float = 0.1, mag_loss_ratio: float = 0.1, optimizer: str = \"Adam\", scheduler: str = \"CosLR\", criterion: str = \"MSE\", epochs: int = 50, starting_epoch: int = 0, learning_rate: float = 0.001, print_freq: int = 100, torch_seed: int | None = None, data_seed: int | None = None, use_device: str | None = None, **kwargs) -> None:\n",
    "        super().__init__(model, targets, energy_loss_ratio, force_loss_ratio, stress_loss_ratio, mag_loss_ratio, optimizer, scheduler, criterion, epochs, starting_epoch, learning_rate, print_freq, torch_seed, data_seed, use_device, **kwargs)\n",
    "        \n",
    "    def train(self, train_loader: DataLoader, val_loader: DataLoader, test_loader: DataLoader | None = None, save_dir: str | None = None, save_test_result: bool = False, train_composition_model: bool = False) -> None:\n",
    "        \"\"\"Train the model using torch data_loaders.\n",
    "\n",
    "        Args:\n",
    "            train_loader (DataLoader): train loader to update CHGNet weights\n",
    "            val_loader (DataLoader): val loader to test accuracy after each epoch\n",
    "            test_loader (DataLoader):  test loader to test accuracy at end of training.\n",
    "                Can be None.\n",
    "                Default = None\n",
    "            save_dir (str): the dir name to save the trained weights\n",
    "                Default = None\n",
    "            save_test_result (bool): Whether to save the test set prediction in a JSON\n",
    "                file. Default = False\n",
    "            train_composition_model (bool): whether to train the composition model\n",
    "                (AtomRef), this is suggested when the fine-tuning dataset has large\n",
    "                elemental energy shift from the pretrained CHGNet, which typically comes\n",
    "                from different DFT pseudo-potentials.\n",
    "                Default = False\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model needs to be initialized\")\n",
    "        global best_checkpoint  # noqa: PLW0603\n",
    "        if save_dir is None:\n",
    "            save_dir = f\"{datetime.now():%Y-%m-%d-%H%M%S}\"\n",
    "            self.save_dir=f\"{datetime.now():%Y-%m-%d-%H%M%S}\"\n",
    "        os.makedirs(f\"results/{save_dir}\", exist_ok=True)\n",
    "        writer = SummaryWriter(log_dir=f\"log/{save_dir}\")\n",
    "\n",
    "        print(f\"Begin Training: using {self.device} device\")\n",
    "        print(f\"training targets: {self.targets}\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # Turn composition model training on / off\n",
    "        for param in self.model.composition_model.parameters():\n",
    "            param.requires_grad = train_composition_model\n",
    "\n",
    "        for epoch in range(self.starting_epoch, self.epochs):\n",
    "            # train\n",
    "            train_mae = self._train(train_loader, epoch)\n",
    "            if \"e\" in train_mae and train_mae[\"e\"] != train_mae[\"e\"]:\n",
    "                print(\"Exit due to NaN\")\n",
    "                break\n",
    "\n",
    "            # val\n",
    "            val_mae = self._validate(val_loader)\n",
    "            for key in self.targets:\n",
    "                self.training_history[key][\"train\"].append(train_mae[key])\n",
    "                self.training_history[key][\"val\"].append(val_mae[key])\n",
    "\n",
    "            if \"e\" in val_mae and val_mae[\"e\"] != val_mae[\"e\"]:\n",
    "                print(\"Exit due to NaN\")\n",
    "                break\n",
    "\n",
    "            self.save_checkpoint(epoch, val_mae, save_dir=save_dir)\n",
    "            for key in self.targets:\n",
    "                self.training_history[key][\"train\"].append(train_mae[key])\n",
    "                self.training_history[key][\"val\"].append(val_mae[key])\n",
    "                # writer.add_scalar(f\"{key}_train_loss\", train_loss / len(dataloader), epoch)\n",
    "                writer.add_scalar(f\"{key}_train_mae\", train_mae[key], epoch)\n",
    "                # writer.add_scalar(f\"{key}_val_loss\", train_loss / len(dataloader), epoch)\n",
    "                writer.add_scalar(f\"{key}_val_mae\", val_mae[key], epoch)\n",
    "\n",
    "        if test_loader is not None:\n",
    "            # test best model\n",
    "            print(\"---------Evaluate Model on Test Set---------------\")\n",
    "            for file in os.listdir(save_dir):\n",
    "                if file.startswith(\"bestE_\"):\n",
    "                    test_file = file\n",
    "                    best_checkpoint = torch.load(os.path.join(save_dir, test_file))\n",
    "\n",
    "            self.model.load_state_dict(best_checkpoint[\"model\"][\"state_dict\"])\n",
    "            if save_test_result:\n",
    "                test_mae = self._validate(\n",
    "                    test_loader, is_test=True, test_result_save_path=save_dir\n",
    "                )\n",
    "            else:\n",
    "                test_mae = self._validate(\n",
    "                    test_loader, is_test=True, test_result_save_path=None\n",
    "                )\n",
    "\n",
    "            for key in self.targets:\n",
    "                self.training_history[key][\"test\"] = test_mae[key]\n",
    "            self.save(filename=os.path.join(save_dir, test_file))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHGNet v0.3.0 initialized with 412,525 parameters\n",
      "CHGNet will run on cuda:0\n"
     ]
    }
   ],
   "source": [
    "from pymatgen.core.structure import Structure\n",
    "import numpy as\n",
    "try:\n",
    "    from chgnet import ROOT\n",
    "\n",
    "    lmo = Structure.from_file(f\"{ROOT}/examples/mp-18767-LiMnO2.cif\")\n",
    "except Exception:\n",
    "    from urllib.request import urlopen\n",
    "\n",
    "    url = \"https://raw.githubusercontent.com/CederGroupHub/chgnet/main/examples/mp-18767-LiMnO2.cif\"\n",
    "    cif = urlopen(url).read().decode(\"utf-8\")\n",
    "    lmo = Structure.from_str(cif, fmt=\"cif\")\n",
    "\n",
    "structures, energies_per_atom, forces, stresses, magmoms = [], [], [], [], []\n",
    "from chgnet.model import CHGNet\n",
    "chgnet = CHGNet.load()\n",
    "\n",
    "for _ in range(100):\n",
    "    structure = lmo.copy()\n",
    "    # stretch the cell by a small amount\n",
    "    structure.apply_strain(np.random.uniform(-0.1, 0.1, size=3))\n",
    "    # perturb all atom positions by a small amount\n",
    "    structure.perturb(0.1)\n",
    "    # print(structure)\n",
    "\n",
    "    pred = chgnet.predict_structure(structure)\n",
    "\n",
    "    structures.append(structure)\n",
    "    energies_per_atom.append(pred[\"e\"] + np.random.uniform(-0.1, 0.1, size=1))\n",
    "    forces.append(pred[\"f\"] + np.random.uniform(-0.01, 0.01, size=pred[\"f\"].shape))\n",
    "    stresses.append(\n",
    "        pred[\"s\"] * -10 + np.random.uniform(-0.05, 0.05, size=pred[\"s\"].shape)\n",
    "    )\n",
    "    magmoms.append(pred[\"m\"] + np.random.uniform(-0.03, 0.03, size=pred[\"m\"].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 structures imported\n"
     ]
    }
   ],
   "source": [
    "from chgnet.data.dataset import StructureData, get_train_val_test_loader\n",
    "dataset = StructureData(\n",
    "    structures=structures,\n",
    "    energies=energies_per_atom,\n",
    "    forces=forces,\n",
    "    stresses=stresses,  # can be None\n",
    "    magmoms=magmoms,  # can be None\n",
    ")\n",
    "train_loader, val_loader, test_loader = get_train_val_test_loader(\n",
    "    dataset, batch_size=32, train_ratio=0.9, val_ratio=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer\n",
    "trainer = TrainerV2(\n",
    "    model=chgnet,\n",
    "    targets=\"efsm\",\n",
    "    optimizer=\"Adam\",\n",
    "    scheduler=\"CosLR\",\n",
    "    criterion=\"MSE\",\n",
    "    epochs=10,\n",
    "    learning_rate=1e-2,\n",
    "    # use_device=\"cuda\",\n",
    "    print_freq=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training: using cuda:0 device\n",
      "training targets: efsm\n",
      "Epoch: [0][1/3] | Time (1.079)(0.158) | Loss 0.0039(0.0039) | MAE e 0.053(0.053)  f 0.005(0.005)  s 0.002(0.002)  m 0.014(0.014)  \n",
      "Epoch: [0][2/3] | Time (0.943)(0.138) | Loss 0.9551(0.4795) | MAE e 0.388(0.220)  f 0.157(0.081)  s 1.347(0.675)  m 0.547(0.280)  \n",
      "*   e_MAE (0.183) \tf_MAE (0.074) \ts_MAE (1.109) \tm_MAE (0.218) \t\n",
      "Epoch: [1][1/3] | Time (0.725)(0.002) | Loss 0.4176(0.4176) | MAE e 0.207(0.207)  f 0.071(0.071)  s 1.101(1.101)  m 0.214(0.214)  \n",
      "Epoch: [1][2/3] | Time (0.752)(0.001) | Loss 0.8245(0.6211) | MAE e 0.095(0.151)  f 0.116(0.094)  s 1.360(1.230)  m 0.375(0.295)  \n",
      "*   e_MAE (0.101) \tf_MAE (0.150) \ts_MAE (1.135) \tm_MAE (0.193) \t\n",
      "Epoch: [2][1/3] | Time (0.745)(0.001) | Loss 0.3914(0.3914) | MAE e 0.070(0.070)  f 0.115(0.115)  s 1.021(1.021)  m 0.167(0.167)  \n",
      "Epoch: [2][2/3] | Time (0.801)(0.001) | Loss 1.0637(0.7276) | MAE e 0.108(0.089)  f 0.174(0.145)  s 1.237(1.129)  m 0.062(0.115)  \n",
      "*   e_MAE (0.117) \tf_MAE (0.059) \ts_MAE (0.509) \tm_MAE (0.216) \t\n",
      "Epoch: [3][1/3] | Time (0.765)(0.002) | Loss 0.0847(0.0847) | MAE e 0.072(0.072)  f 0.067(0.067)  s 0.442(0.442)  m 0.207(0.207)  \n",
      "Epoch: [3][2/3] | Time (0.779)(0.001) | Loss 0.3476(0.2162) | MAE e 0.092(0.082)  f 0.067(0.067)  s 0.871(0.657)  m 0.231(0.219)  \n",
      "*   e_MAE (0.082) \tf_MAE (0.056) \ts_MAE (0.858) \tm_MAE (0.090) \t\n",
      "Epoch: [4][1/3] | Time (0.751)(0.001) | Loss 0.1363(0.1363) | MAE e 0.065(0.065)  f 0.066(0.066)  s 0.588(0.588)  m 0.082(0.082)  \n",
      "Epoch: [4][2/3] | Time (0.743)(0.001) | Loss 0.1293(0.1328) | MAE e 0.068(0.067)  f 0.082(0.074)  s 0.566(0.577)  m 0.043(0.063)  \n",
      "*   e_MAE (0.056) \tf_MAE (0.104) \ts_MAE (0.854) \tm_MAE (0.155) \t\n",
      "Epoch: [5][1/3] | Time (0.806)(0.002) | Loss 0.4029(0.4029) | MAE e 0.067(0.067)  f 0.118(0.118)  s 0.927(0.927)  m 0.159(0.159)  \n",
      "Epoch: [5][2/3] | Time (0.782)(0.002) | Loss 0.1697(0.2863) | MAE e 0.059(0.063)  f 0.104(0.111)  s 0.644(0.785)  m 0.152(0.155)  \n",
      "*   e_MAE (0.052) \tf_MAE (0.084) \ts_MAE (0.752) \tm_MAE (0.085) \t\n",
      "Epoch: [6][1/3] | Time (0.789)(0.001) | Loss 0.1368(0.1368) | MAE e 0.056(0.056)  f 0.085(0.085)  s 0.641(0.641)  m 0.079(0.079)  \n",
      "Epoch: [6][2/3] | Time (0.861)(0.001) | Loss 0.2218(0.1793) | MAE e 0.056(0.056)  f 0.081(0.083)  s 0.648(0.645)  m 0.040(0.060)  \n",
      "*   e_MAE (0.041) \tf_MAE (0.056) \ts_MAE (0.425) \tm_MAE (0.086) \t\n",
      "Epoch: [7][1/3] | Time (0.766)(0.001) | Loss 0.0838(0.0838) | MAE e 0.057(0.057)  f 0.061(0.061)  s 0.526(0.526)  m 0.089(0.089)  \n",
      "Epoch: [7][2/3] | Time (0.782)(0.002) | Loss 0.1364(0.1101) | MAE e 0.052(0.055)  f 0.063(0.062)  s 0.612(0.569)  m 0.115(0.102)  \n",
      "*   e_MAE (0.039) \tf_MAE (0.062) \ts_MAE (0.484) \tm_MAE (0.062) \t\n",
      "Epoch: [8][1/3] | Time (0.740)(0.002) | Loss 0.0724(0.0724) | MAE e 0.051(0.051)  f 0.060(0.060)  s 0.380(0.380)  m 0.063(0.063)  \n",
      "Epoch: [8][2/3] | Time (0.751)(0.001) | Loss 0.0679(0.0701) | MAE e 0.060(0.056)  f 0.064(0.062)  s 0.420(0.400)  m 0.033(0.048)  \n",
      "*   e_MAE (0.043) \tf_MAE (0.062) \ts_MAE (0.687) \tm_MAE (0.054) \t\n",
      "Epoch: [9][1/3] | Time (0.833)(0.001) | Loss 0.1062(0.1062) | MAE e 0.049(0.049)  f 0.058(0.058)  s 0.602(0.602)  m 0.051(0.051)  \n",
      "Epoch: [9][2/3] | Time (0.822)(0.001) | Loss 0.1083(0.1073) | MAE e 0.052(0.051)  f 0.058(0.058)  s 0.615(0.609)  m 0.078(0.065)  \n",
      "*   e_MAE (0.043) \tf_MAE (0.063) \ts_MAE (0.418) \tm_MAE (0.066) \t\n",
      "---------Evaluate Model on Test Set---------------\n",
      "**  e_MAE (0.071) \tf_MAE (0.072) \ts_MAE (0.512) \tm_MAE (0.057) \t\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
